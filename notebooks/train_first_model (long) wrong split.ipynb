{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sensitive-romance",
   "metadata": {},
   "source": [
    "### This notebook is intended for demonstration purposes only. \n",
    "The code might not be maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increased-bronze",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "large-lingerie",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import random\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silver-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, Dropout, BatchNormalization, MaxPooling1D, LeakyReLU\n",
    "\n",
    "class Base(Layer):\n",
    "    def __init__(self, h_params, nb_classes, batch_size, variant, activation):\n",
    "        super(Base, self).__init__()\n",
    "\n",
    "        self.model = None\n",
    "        self.__previous_models = None\n",
    "        self.__input_shape = None\n",
    "\n",
    "        self.__h_params = h_params\n",
    "        self.__activation = activation\n",
    "        self.__variant = variant\n",
    "        self.__nb_classes = nb_classes\n",
    "        self.__batch_size = batch_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        exit('The function `build` needs to be implemented. This is an abstract class.')\n",
    "\n",
    "    def get_model_name(self):\n",
    "        exit('`get_model_name` needs to be implemented. This is an abstract class.')\n",
    "\n",
    "    @property\n",
    "    def variant(self):\n",
    "        return self.__variant\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self.__batch_size\n",
    "\n",
    "    @property\n",
    "    def nb_classes(self):\n",
    "        return self.__nb_classes\n",
    "\n",
    "    @property\n",
    "    def input_shape(self):\n",
    "        return self.__input_shape\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self.__activation\n",
    "\n",
    "    @property\n",
    "    def h_params(self):\n",
    "        return self.__h_params\n",
    "\n",
    "    @property\n",
    "    def n_epochs(self):\n",
    "        return self.__h_params['n_epochs']\n",
    "\n",
    "    @property\n",
    "    def wd(self):\n",
    "        return self.__h_params['wd']\n",
    "\n",
    "    @property\n",
    "    def l1(self):\n",
    "        return self.__h_params['l1']\n",
    "\n",
    "    @variant.setter\n",
    "    def variant(self, variant):\n",
    "        self.__variant = variant\n",
    "\n",
    "    @batch_size.setter\n",
    "    def batch_size(self, batch_size):\n",
    "        self.__batch_size = batch_size\n",
    "\n",
    "    @nb_classes.setter\n",
    "    def nb_classes(self, nb_classes):\n",
    "        self.__nb_classes = nb_classes\n",
    "\n",
    "    @input_shape.setter\n",
    "    def input_shape(self, input_shape):\n",
    "        self.__input_shape = input_shape\n",
    "\n",
    "    @activation.setter\n",
    "    def activation(self, activation):\n",
    "        self.__activation = activation\n",
    "\n",
    "    @h_params.setter\n",
    "    def h_params(self, h_params):\n",
    "        self.__h_params = h_params\n",
    "\n",
    "    @n_epochs.setter\n",
    "    def n_epochs(self, n_epochs):\n",
    "        self.__h_params['n_epochs'] = n_epochs\n",
    "\n",
    "    @wd.setter\n",
    "    def wd(self, wd):\n",
    "        self.__h_params['wd'] = wd\n",
    "\n",
    "    @l1.setter\n",
    "    def l1(self, l1):\n",
    "        self.__h_params['l1'] = l1\n",
    "\n",
    "\n",
    "class CNN(Base):\n",
    "    def __init__(self, h_params, nb_classes, batch_size, variant='lecun', activation='relu'):\n",
    "        super(CNN, self).__init__(h_params, nb_classes, batch_size, variant, activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        if self.variant == 'lecun':\n",
    "            self.lecun()\n",
    "        elif self.variant == 'lenet':\n",
    "            self.lenet()\n",
    "        elif self.variant == 'vgg9':\n",
    "            self.vgg9()\n",
    "        else:\n",
    "            exit(f'Model {self.variant} unrecognized.\\n Accepted variants: lecun, lenet and vgg9')\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"CNN\"\n",
    "\n",
    "    def lecun(self):\n",
    "        try:\n",
    "            assert self.nb_classes is not None\n",
    "        except ValueError:\n",
    "            exit(\"Must set the number of classes first\")\n",
    "        self.model = Sequential([\n",
    "            Conv1D(filters=6, kernel_size=21, strides=1, padding='same', activation='relu',\n",
    "                   input_shape=self.input_shape, kernel_initializer=keras.initializers.he_normal(), activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Conv1D(filters=16, kernel_size=5, strides=1, padding='same', activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(120, activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            Dense(84, activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            Dense(self.nb_classes, activation='softmax', activity_regularizer=l1_l2(self.l1, self.wd))  # or Activation('softmax')\n",
    "        ])\n",
    "\n",
    "    def lenet(self):\n",
    "        self.model = Sequential([\n",
    "            Conv1D(filters=16, kernel_size=21, strides=1, padding='same', input_shape=self.input_shape,\n",
    "                   kernel_initializer=keras.initializers.he_normal(), activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            LeakyReLU(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Conv1D(filters=32, kernel_size=11, strides=1, padding='same', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            LeakyReLU(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Conv1D(filters=64, kernel_size=5, strides=1, padding='same', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            LeakyReLU(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(2050, activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            Dropout(0.5),\n",
    "            Dense(self.nb_classes, activation='softmax', activity_regularizer=l1_l2(self.l1, self.wd))  # or Activation('softmax')\n",
    "        ])\n",
    "\n",
    "    def vgg9(self):\n",
    "        self.model = Sequential([\n",
    "            Conv1D(filters=64, kernel_size=21, strides=1, padding='same', activation='relu',\n",
    "                   input_shape=self.input_shape, kernel_initializer=keras.initializers.he_normal(), activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            Conv1D(filters=64, kernel_size=21, strides=1, padding='same', activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Conv1D(filters=128, kernel_size=11, strides=1, padding='same', activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            Conv1D(filters=128, kernel_size=11, strides=1, padding='same', activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Conv1D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            Conv1D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(4096, activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            Dropout(0.5),\n",
    "            Dense(4096, activation='relu', activity_regularizer=l1_l2(self.l1, self.wd)),\n",
    "            Dropout(0.5),\n",
    "            Dense(self.nb_classes, activation='softmax', activity_regularizer=l1_l2(self.l1, self.wd))  # or Activation('softmax')\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southwest-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_data(fname):\n",
    "    from sklearn.preprocessing import minmax_scale\n",
    "    mat_data = pd.read_csv(fname)\n",
    "    labels = mat_data.index.values\n",
    "    categories = [int(lab.split('_')[1]) for lab in labels]\n",
    "    labels = [lab.split('_')[0] for lab in labels]\n",
    "    mat_data = np.asarray(mat_data)\n",
    "    mat_data = minmax_scale(mat_data, axis=0, feature_range=(0, 1))\n",
    "    mat_data = mat_data.astype(\"float32\")\n",
    "    return mat_data, labels, categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-bosnia",
   "metadata": {},
   "source": [
    "### Matthews Correlation Coefficient  (MCC)\n",
    "<br><br>\n",
    "$MCC = \\dfrac{TP \\times TN - FP \\times FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}} $\n",
    "\n",
    "$N = TN + TP + FN + FP$\n",
    "<br><br>\n",
    "$S = \\dfrac{TP + FN}{N}$\n",
    "<br><br>\n",
    "$P = \\dfrac{TP + FP}{N}$\n",
    "<br><br>\n",
    "$MCC = \\dfrac{TP/N - S \\times P}{\\sqrt{PS(1 - S)(1 - P)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-giant",
   "metadata": {},
   "source": [
    "## Functions to compute MCC, sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "american-program",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# TODO use keras_confusion_matrix for everything\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def keras_confusion_matrix(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "#  matthews correlation coefficient\n",
    "def mcc(y_true, y_pred):\n",
    "    tp, tn, fp, fn = keras_confusion_matrix(y_true, y_pred)\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tp, _, fp, fn = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tp, tn, fp, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-harvard",
   "metadata": {},
   "source": [
    "## Save logs with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-journey",
   "metadata": {},
   "source": [
    "### Configuration of the hyperparameters and metrics to log with tensorboard  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signal-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "class TensorboardLogging:\n",
    "\n",
    "    def __init__(self, hparams_filepath, params):\n",
    "        self.params = params\n",
    "        self.hparams_filepath = hparams_filepath\n",
    "        HP_EPOCHS = hp.HParam('epochs', hp.IntInterval(1, 50))\n",
    "        HP_LR = hp.HParam('lr', hp.RealInterval(1e-6, 1e-3))\n",
    "        HP_WD = hp.HParam('wd', hp.RealInterval(1e-8, 1e-3))\n",
    "        HP_BS = hp.HParam('bs', hp.IntInterval(1, 512))\n",
    "        HPARAMS = [HP_EPOCHS, HP_LR, HP_WD, HP_BS]\n",
    "        with tf.summary.create_file_writer(hparams_filepath).as_default():\n",
    "            hp.hparams_config(\n",
    "                hparams=HPARAMS,\n",
    "                metrics=[\n",
    "                    hp.Metric('train_accuracy', display_name='Train Accuracy'),\n",
    "                    hp.Metric('valid_accuracy', display_name='Valid Accuracy'),\n",
    "                    hp.Metric('test_accuracy', display_name='Test Accuracy'),\n",
    "                    hp.Metric('train_loss', display_name='Train Loss'),\n",
    "                    hp.Metric('valid_loss', display_name='Valid Loss'),\n",
    "                    hp.Metric('test_loss', display_name='Test Loss'),\n",
    "                    hp.Metric('train_mcc', display_name='Train MCC'),\n",
    "                    hp.Metric('valid_mcc', display_name='Valid MCC'),\n",
    "                    hp.Metric('test_mcc', display_name='Test MCC')\n",
    "                ],\n",
    "            )\n",
    "\n",
    "    def logging(self, traces):\n",
    "        epochs = self.params['n_epochs']\n",
    "        lr = self.params['lr']\n",
    "        wd = self.params['wd']\n",
    "        bs = self.params['bs']\n",
    "        l1 = self.params['l1']\n",
    "        with tf.summary.create_file_writer(self.hparams_filepath).as_default():\n",
    "            hp.hparams({\n",
    "                'epochs': epochs,\n",
    "                'lr': lr,\n",
    "                'wd': wd,\n",
    "                'bs': bs,\n",
    "                'l1': l1,\n",
    "            })  # record the values used in this trial\n",
    "            tf.summary.scalar('train_accuracy', np.mean([np.mean(x) for x in traces['train']['accuracies']]), step=1)\n",
    "            tf.summary.scalar('valid_accuracy', np.mean(traces['valid']['accuracies']), step=1)\n",
    "            tf.summary.scalar('test_accuracy', np.mean(traces['test']['accuracies']), step=1)\n",
    "            tf.summary.scalar('train_loss', np.mean([np.mean(x) for x in traces['train']['losses']]), step=1)\n",
    "            tf.summary.scalar('valid_loss', np.mean(traces['valid']['losses']), step=1)\n",
    "            tf.summary.scalar('test_loss', np.mean(traces['test']['losses']), step=1)\n",
    "            tf.summary.scalar('train_mcc', np.mean([np.mean(x) for x in traces['train']['mccs']]), step=1)\n",
    "            tf.summary.scalar('valid_mcc', np.mean(traces['valid']['mccs']), step=1)\n",
    "            tf.summary.scalar('test_mcc', np.mean(traces['test']['mccs']), step=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-applicant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ranking-eleven",
   "metadata": {},
   "source": [
    "The following function is used to log the results with Tensorboard for each hyperparameters combinations in the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-insider",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "built-engagement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab number</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>OCR number</th>\n",
       "      <th>Reception date</th>\n",
       "      <th>Tissue nature</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Pathological type</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Adicap code</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Age</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H15-3523</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Articular capsule of the knee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Myxosarcoma</td>\n",
       "      <td>Grade I</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Cavalier King charles</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Right back limb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ds</td>\n",
       "      <td>2.0</td>\n",
       "      <td>H15-3263</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Superficial dermis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade III</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Cane Corso</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Perianal mass, invading the sub-cutaneous tissues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ds</td>\n",
       "      <td>3.0</td>\n",
       "      <td>H15-2015</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hemangiopericytoma</td>\n",
       "      <td>Grade I</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Golder Retriever</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ds</td>\n",
       "      <td>4.0</td>\n",
       "      <td>H15-1570</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MPNST</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Crossbreed</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Left axillary region. \"Malignant Peripheral Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ds</td>\n",
       "      <td>5.0</td>\n",
       "      <td>H15-1480</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Beagle</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Right back limb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ds</td>\n",
       "      <td>6.0</td>\n",
       "      <td>H15-1457</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Mucosal chorion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Golder Retriever</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Labial mass, infiltrating the underneath muscu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ds</td>\n",
       "      <td>7.0</td>\n",
       "      <td>H15-1289</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Golder Retriever</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Shoulder mass. Recurrence. May be a MPNST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ds</td>\n",
       "      <td>8.0</td>\n",
       "      <td>H15-1234</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Bone</td>\n",
       "      <td>Osteoblastic</td>\n",
       "      <td>Osteosarcoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BH</td>\n",
       "      <td>LO</td>\n",
       "      <td>Q7A0</td>\n",
       "      <td>Bouledogue Français</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mandibular bone. Infiltrating the mucosal chorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ds</td>\n",
       "      <td>9.0</td>\n",
       "      <td>H15-1048</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Lung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indifferenciated</td>\n",
       "      <td>Grade III</td>\n",
       "      <td>OH</td>\n",
       "      <td>RP</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Shetland</td>\n",
       "      <td>8.0</td>\n",
       "      <td>90% Necrosis so difficult to diagnose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ds</td>\n",
       "      <td>10.0</td>\n",
       "      <td>H15-0037</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Mesenchymal tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Berger Allemand</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Recurrence. Infiltrating the surrounding soft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ds</td>\n",
       "      <td>11.0</td>\n",
       "      <td>H15-2397</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indifferenciated</td>\n",
       "      <td>Grade III</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Setter</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Left anterior limb. Massively infiltrating. &gt;5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ds</td>\n",
       "      <td>12.0</td>\n",
       "      <td>H15-2364</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhabdomyosarcoma</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Fox Terrier</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No subtype determined by IHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ds</td>\n",
       "      <td>13.0</td>\n",
       "      <td>H15-1767</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Bone</td>\n",
       "      <td>Osteoblastic and chondroblastic</td>\n",
       "      <td>Osteosarcoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>LO</td>\n",
       "      <td>Q7A0</td>\n",
       "      <td>Bouledogue Américain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One of the back limbs. Loci of cartilagoid matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ds</td>\n",
       "      <td>14.0</td>\n",
       "      <td>H15-1475</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Omentum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indifferenciated</td>\n",
       "      <td>Grade III</td>\n",
       "      <td>OH</td>\n",
       "      <td>XA</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Labrador</td>\n",
       "      <td>11.0</td>\n",
       "      <td>No subtype determined by IHC. &lt;50% Necrosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ds</td>\n",
       "      <td>15.0</td>\n",
       "      <td>H15-1184</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Bone</td>\n",
       "      <td>Osteoblastic</td>\n",
       "      <td>Osteosarcoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>LO</td>\n",
       "      <td>Q7A0</td>\n",
       "      <td>Dogue Allemands</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Presence of osteoïd matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ds</td>\n",
       "      <td>16.0</td>\n",
       "      <td>H15-1130</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Bone</td>\n",
       "      <td>Osteoblastic</td>\n",
       "      <td>Osteosarcoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>LO</td>\n",
       "      <td>Q7A0</td>\n",
       "      <td>Berger Belge Groenendael</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Costal bone. Same amount of cartilagoid and os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ds</td>\n",
       "      <td>17.0</td>\n",
       "      <td>H15-1950</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Cutaneous and subcutaneous tissues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hemangiopericytoma</td>\n",
       "      <td>Grade I</td>\n",
       "      <td>OH</td>\n",
       "      <td>TZ</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Braque Allemand</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Right buttock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ds</td>\n",
       "      <td>18.0</td>\n",
       "      <td>H15-1701</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>Bone</td>\n",
       "      <td>Osteoblastic</td>\n",
       "      <td>Osteosarcoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BH</td>\n",
       "      <td>LO</td>\n",
       "      <td>Q7A0</td>\n",
       "      <td>Dogue Argentin</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Moderate osteoid matrix production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ds</td>\n",
       "      <td>19.0</td>\n",
       "      <td>H14-0697</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Spleen</td>\n",
       "      <td>Fibrohistiocytic</td>\n",
       "      <td>splenic sarcoma</td>\n",
       "      <td>Grade III</td>\n",
       "      <td>OH</td>\n",
       "      <td>SR</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Cocker</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Huge metastasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ds</td>\n",
       "      <td>20.0</td>\n",
       "      <td>H14-1242</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Lung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Histiocytic sarcoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>RP</td>\n",
       "      <td>X7K2</td>\n",
       "      <td>Bouvier Bernois</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ds</td>\n",
       "      <td>21.0</td>\n",
       "      <td>H15-1687</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Mucosal chorion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade II</td>\n",
       "      <td>OH</td>\n",
       "      <td>GG</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Vaginal mass, infiltrating, Necrosis and  hemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ds</td>\n",
       "      <td>22.0</td>\n",
       "      <td>H16-0812</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Cutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indifferenciated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K4</td>\n",
       "      <td>Border Collie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This tumor could be a : Giant cell anaplastic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ds</td>\n",
       "      <td>23.0</td>\n",
       "      <td>H16-1124</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibrosarcoma</td>\n",
       "      <td>Grade I</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Springer Anglais</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ds</td>\n",
       "      <td>24.0</td>\n",
       "      <td>H16-1397</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Digestive tract</td>\n",
       "      <td>Spindle-shaped</td>\n",
       "      <td>GIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Bobtail</td>\n",
       "      <td>7.0</td>\n",
       "      <td>\"GastroIntestinal Stromal Tumor\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ds</td>\n",
       "      <td>25.0</td>\n",
       "      <td>H16-1707</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>Subcutaneous tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indifferenciated</td>\n",
       "      <td>Grade III</td>\n",
       "      <td>OH</td>\n",
       "      <td>OT</td>\n",
       "      <td>X7K0</td>\n",
       "      <td>Teckel</td>\n",
       "      <td>8.0</td>\n",
       "      <td>&gt;50% necrotic changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ds</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ds</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ds</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ds</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ds</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ds</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ds</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ds</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgery : 20161202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lab number  Unnamed: 1 OCR number Reception date  \\\n",
       "0          Ds         1.0   H15-3523     2016-05-12   \n",
       "1          Ds         2.0   H15-3263     2016-05-12   \n",
       "2          Ds         3.0   H15-2015     2016-05-12   \n",
       "3          Ds         4.0   H15-1570     2016-05-12   \n",
       "4          Ds         5.0   H15-1480     2016-05-12   \n",
       "5          Ds         6.0   H15-1457     2016-05-12   \n",
       "6          Ds         7.0   H15-1289     2016-05-12   \n",
       "7          Ds         8.0   H15-1234     2016-05-12   \n",
       "8          Ds         9.0   H15-1048     2016-05-12   \n",
       "9          Ds        10.0   H15-0037     2016-05-12   \n",
       "10         Ds        11.0   H15-2397     2016-05-12   \n",
       "11         Ds        12.0   H15-2364     2016-05-12   \n",
       "12         Ds        13.0   H15-1767     2016-05-12   \n",
       "13         Ds        14.0   H15-1475     2016-05-12   \n",
       "14         Ds        15.0   H15-1184     2016-05-12   \n",
       "15         Ds        16.0   H15-1130     2016-05-12   \n",
       "16         Ds        17.0   H15-1950     2016-05-12   \n",
       "17         Ds        18.0   H15-1701     2016-05-12   \n",
       "18         Ds        19.0   H14-0697     2016-11-28   \n",
       "19         Ds        20.0   H14-1242     2016-11-28   \n",
       "20         Ds        21.0   H15-1687     2016-11-28   \n",
       "21         Ds        22.0   H16-0812     2016-11-28   \n",
       "22         Ds        23.0   H16-1124     2016-11-28   \n",
       "23         Ds        24.0   H16-1397     2016-11-28   \n",
       "24         Ds        25.0   H16-1707     2016-11-28   \n",
       "25         Ds        26.0        NaN     2016-12-09   \n",
       "26         Ds        27.0        NaN     2016-12-09   \n",
       "27         Ds        28.0        NaN     2016-12-09   \n",
       "28         Ds        29.0        NaN     2016-12-09   \n",
       "29         Ds        30.0        NaN     2016-12-09   \n",
       "30         Ds        31.0        NaN     2016-12-09   \n",
       "31         Ds        32.0        NaN     2016-12-09   \n",
       "32         Ds        33.0        NaN     2016-12-09   \n",
       "\n",
       "                         Tissue nature                          Subtype  \\\n",
       "0        Articular capsule of the knee                              NaN   \n",
       "1                   Superficial dermis                              NaN   \n",
       "2                  Subcutaneous tissue                              NaN   \n",
       "3                  Subcutaneous tissue                              NaN   \n",
       "4                  Subcutaneous tissue                              NaN   \n",
       "5                      Mucosal chorion                              NaN   \n",
       "6                                  NaN                              NaN   \n",
       "7                                 Bone                     Osteoblastic   \n",
       "8                                 Lung                              NaN   \n",
       "9                   Mesenchymal tissue                              NaN   \n",
       "10                 Subcutaneous tissue                              NaN   \n",
       "11                 Subcutaneous tissue                              NaN   \n",
       "12                                Bone  Osteoblastic and chondroblastic   \n",
       "13                             Omentum                              NaN   \n",
       "14                                Bone                     Osteoblastic   \n",
       "15                                Bone                     Osteoblastic   \n",
       "16  Cutaneous and subcutaneous tissues                              NaN   \n",
       "17                                Bone                     Osteoblastic   \n",
       "18                              Spleen                 Fibrohistiocytic   \n",
       "19                                Lung                              NaN   \n",
       "20                     Mucosal chorion                              NaN   \n",
       "21                    Cutaneous tissue                              NaN   \n",
       "22                 Subcutaneous tissue                              NaN   \n",
       "23                     Digestive tract                   Spindle-shaped   \n",
       "24                 Subcutaneous tissue                              NaN   \n",
       "25                                 NaN                              NaN   \n",
       "26                                 NaN                              NaN   \n",
       "27                                 NaN                              NaN   \n",
       "28                                 NaN                              NaN   \n",
       "29                                 NaN                              NaN   \n",
       "30                                 NaN                              NaN   \n",
       "31                                 NaN                              NaN   \n",
       "32                                 NaN                              NaN   \n",
       "\n",
       "      Pathological type Classification Adicap code Unnamed: 9 Unnamed: 10  \\\n",
       "0           Myxosarcoma        Grade I          OH         TZ        X7K0   \n",
       "1          Fibrosarcoma      Grade III          OH         TZ        X7K0   \n",
       "2    Hemangiopericytoma        Grade I          OH         TZ        X7K0   \n",
       "3                 MPNST       Grade II          OH         TZ        X7K0   \n",
       "4          Fibrosarcoma       Grade II          OH         TZ        X7K0   \n",
       "5          Fibrosarcoma       Grade II          OH         OT        X7K0   \n",
       "6          Fibrosarcoma       Grade II          OH         OT        X7K0   \n",
       "7          Osteosarcoma            NaN          BH         LO        Q7A0   \n",
       "8      Indifferenciated      Grade III          OH         RP        X7K0   \n",
       "9          Fibrosarcoma       Grade II          OH         OT        X7K0   \n",
       "10     Indifferenciated      Grade III          OH         TZ        X7K0   \n",
       "11     Rhabdomyosarcoma       Grade II          OH         TZ        X7K0   \n",
       "12         Osteosarcoma            NaN          OH         LO        Q7A0   \n",
       "13     Indifferenciated      Grade III          OH         XA        X7K0   \n",
       "14         Osteosarcoma            NaN          OH         LO        Q7A0   \n",
       "15         Osteosarcoma            NaN          OH         LO        Q7A0   \n",
       "16   Hemangiopericytoma        Grade I          OH         TZ        X7K0   \n",
       "17         Osteosarcoma            NaN          BH         LO        Q7A0   \n",
       "18      splenic sarcoma      Grade III          OH         SR        X7K0   \n",
       "19  Histiocytic sarcoma            NaN          OH         RP        X7K2   \n",
       "20         Fibrosarcoma       Grade II          OH         GG        X7K0   \n",
       "21     Indifferenciated            NaN          OH         OT        X7K4   \n",
       "22         Fibrosarcoma        Grade I          OH         OT        X7K0   \n",
       "23                 GIST            NaN          OH         OT        X7K0   \n",
       "24     Indifferenciated      Grade III          OH         OT        X7K0   \n",
       "25               Normal            NaN         NaN        NaN         NaN   \n",
       "26               Normal            NaN         NaN        NaN         NaN   \n",
       "27               Normal            NaN         NaN        NaN         NaN   \n",
       "28               Normal            NaN         NaN        NaN         NaN   \n",
       "29               Normal            NaN         NaN        NaN         NaN   \n",
       "30               Normal            NaN         NaN        NaN         NaN   \n",
       "31               Normal            NaN         NaN        NaN         NaN   \n",
       "32               Normal            NaN         NaN        NaN         NaN   \n",
       "\n",
       "                       Breed   Age  \\\n",
       "0      Cavalier King charles   6.0   \n",
       "1                 Cane Corso   8.0   \n",
       "2           Golder Retriever  10.0   \n",
       "3                 Crossbreed  10.0   \n",
       "4                     Beagle  10.0   \n",
       "5           Golder Retriever   7.0   \n",
       "6           Golder Retriever  12.0   \n",
       "7        Bouledogue Français   9.0   \n",
       "8                   Shetland   8.0   \n",
       "9            Berger Allemand  12.0   \n",
       "10                    Setter  12.0   \n",
       "11               Fox Terrier  15.0   \n",
       "12      Bouledogue Américain   NaN   \n",
       "13                  Labrador  11.0   \n",
       "14           Dogue Allemands   4.0   \n",
       "15  Berger Belge Groenendael   2.0   \n",
       "16           Braque Allemand   9.0   \n",
       "17            Dogue Argentin   7.0   \n",
       "18                    Cocker  10.0   \n",
       "19           Bouvier Bernois  10.0   \n",
       "20                Rottweiler   9.0   \n",
       "21             Border Collie   5.0   \n",
       "22          Springer Anglais   5.0   \n",
       "23                   Bobtail   7.0   \n",
       "24                    Teckel   8.0   \n",
       "25                       NaN   NaN   \n",
       "26                       NaN   NaN   \n",
       "27                       NaN   NaN   \n",
       "28                       NaN   NaN   \n",
       "29                       NaN   NaN   \n",
       "30                       NaN   NaN   \n",
       "31                       NaN   NaN   \n",
       "32                       NaN   NaN   \n",
       "\n",
       "                                                Notes  \n",
       "0                                     Right back limb  \n",
       "1   Perianal mass, invading the sub-cutaneous tissues  \n",
       "2                                                 NaN  \n",
       "3   Left axillary region. \"Malignant Peripheral Ne...  \n",
       "4                                     Right back limb  \n",
       "5   Labial mass, infiltrating the underneath muscu...  \n",
       "6           Shoulder mass. Recurrence. May be a MPNST  \n",
       "7   Mandibular bone. Infiltrating the mucosal chorion  \n",
       "8               90% Necrosis so difficult to diagnose  \n",
       "9   Recurrence. Infiltrating the surrounding soft ...  \n",
       "10  Left anterior limb. Massively infiltrating. >5...  \n",
       "11                       No subtype determined by IHC  \n",
       "12  One of the back limbs. Loci of cartilagoid matrix  \n",
       "13        No subtype determined by IHC. <50% Necrosis  \n",
       "14                         Presence of osteoïd matrix  \n",
       "15  Costal bone. Same amount of cartilagoid and os...  \n",
       "16                                      Right buttock  \n",
       "17                 Moderate osteoid matrix production  \n",
       "18                                    Huge metastasis  \n",
       "19                                                NaN  \n",
       "20  Vaginal mass, infiltrating, Necrosis and  hemo...  \n",
       "21  This tumor could be a : Giant cell anaplastic ...  \n",
       "22                                                NaN  \n",
       "23                   \"GastroIntestinal Stromal Tumor\"  \n",
       "24                              >50% necrotic changes  \n",
       "25                                 Surgery : 20161201  \n",
       "26                                 Surgery : 20161128  \n",
       "27                                 Surgery : 20161201  \n",
       "28                                 Surgery : 20161129  \n",
       "29                                 Surgery : 20161206  \n",
       "30                                 Surgery : 20161129  \n",
       "31                                 Surgery : 20161201  \n",
       "32                                 Surgery : 20161202  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('D:\\\\workbench\\\\data\\\\spectro\\\\Canis\\\\mmc2.xlsx')\n",
    "df = df[df['Unnamed: 1'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "standing-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, samples = ms_data('data/canis_intensities.csv')\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "growing-privacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Myxosarcoma': 60,\n",
       " 'Fibrosarcoma': 473,\n",
       " 'Indifferenciated': 376,\n",
       " 'Rhabdomyosarcoma': 66,\n",
       " 'Osteosarcoma': 339,\n",
       " 'Hemangiopericytoma': 134,\n",
       " 'splenic sarcoma': 63,\n",
       " 'Histiocytic sarcoma': 105,\n",
       " 'GIST': 70,\n",
       " 'Normal': 482,\n",
       " 'MPNST': 60}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "for label in labels:\n",
    "    if label not in labels_dict:\n",
    "        labels_dict[label] = 1\n",
    "    else:\n",
    "        labels_dict[label] += 1\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "favorite-wilson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Myxosarcoma_1': 60,\n",
       " 'Fibrosarcoma_10': 71,\n",
       " 'Indifferenciated_11': 78,\n",
       " 'Rhabdomyosarcoma_12': 66,\n",
       " 'Osteosarcoma_13': 69,\n",
       " 'Indifferenciated_14': 72,\n",
       " 'Osteosarcoma_15': 65,\n",
       " 'Osteosarcoma_16': 71,\n",
       " 'Hemangiopericytoma_17': 76,\n",
       " 'Osteosarcoma_18': 71,\n",
       " 'splenic sarcoma_19': 63,\n",
       " 'Fibrosarcoma_2': 65,\n",
       " 'Histiocytic sarcoma_20': 105,\n",
       " 'Fibrosarcoma_21': 64,\n",
       " 'Indifferenciated_22': 99,\n",
       " 'Fibrosarcoma_23': 69,\n",
       " 'GIST_24': 70,\n",
       " 'Indifferenciated_25': 60,\n",
       " 'Normal_26': 68,\n",
       " 'Normal_27': 73,\n",
       " 'Normal_28': 60,\n",
       " 'Normal_29': 60,\n",
       " 'Hemangiopericytoma_3': 58,\n",
       " 'Normal_30': 60,\n",
       " 'Normal_31': 46,\n",
       " 'Normal_32': 60,\n",
       " 'Normal_33': 55,\n",
       " 'MPNST_4': 60,\n",
       " 'Fibrosarcoma_5': 64,\n",
       " 'Fibrosarcoma_6': 62,\n",
       " 'Fibrosarcoma_7': 78,\n",
       " 'Osteosarcoma_8': 63,\n",
       " 'Indifferenciated_9': 67}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_dict = {}\n",
    "for label, sample in zip(labels, samples):\n",
    "    name = f\"{label}_{sample}\"\n",
    "    if name not in samples_dict:\n",
    "        samples_dict[name] = 1\n",
    "    else:\n",
    "        samples_dict[name] += 1\n",
    "samples_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "treated-camping",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample  category       label\n",
       "0          1         1  Not Normal\n",
       "1          1         1  Not Normal\n",
       "2          1         1  Not Normal\n",
       "3          1         1  Not Normal\n",
       "4          1         1  Not Normal\n",
       "...      ...       ...         ...\n",
       "2223       9         1  Not Normal\n",
       "2224       9         1  Not Normal\n",
       "2225       9         1  Not Normal\n",
       "2226       9         1  Not Normal\n",
       "2227       9         1  Not Normal\n",
       "\n",
       "[2228 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Normal' in labels:\n",
    "    for i, label in enumerate(labels):\n",
    "        if label != 'Normal':\n",
    "            labels[i] = 'Not Normal'\n",
    "\n",
    "categories = pd.Categorical(labels).codes\n",
    "labels = pd.concat([\n",
    "    pd.DataFrame(np.array(samples).reshape([-1, 1])),\n",
    "    pd.DataFrame(np.array(categories).reshape([-1, 1])),\n",
    "    pd.DataFrame(np.array(labels).reshape([-1, 1])),\n",
    "], 1)\n",
    "labels.columns = ['sample', 'category', 'label']\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-industry",
   "metadata": {},
   "source": [
    "# How many sample per class is there really?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "convenient-arizona",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "separated-divorce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal', 'Not Normal'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlikely-answer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "steady-carroll",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(\n",
    "            self,\n",
    "            intensities_file,\n",
    "            cumulative_step,\n",
    "            criterion='categorical_crossentropy',\n",
    "            variant='logistic',\n",
    "            get_data_function=ms_data,\n",
    "            n_channels=1,\n",
    "            save_train_models=True,\n",
    "            model_name=CNN,\n",
    "            verbose=0,\n",
    "            model_path=False,\n",
    "            freeze=True,\n",
    "            retrain=False,\n",
    "    ):\n",
    "        self.dataset_name = intensities_file.split('/')[-1].split('_')[0]\n",
    "        self.freeze = freeze\n",
    "        self.verbose = verbose\n",
    "        self.variant = variant\n",
    "        self.retrain = retrain\n",
    "        self.cumulative_step = cumulative_step\n",
    "        self.model_name = model_name\n",
    "        self.save_train_models = save_train_models\n",
    "        self.data, labels, samples = get_data_function(intensities_file)\n",
    "        self.data[np.isnan(self.data)] = 0\n",
    "\n",
    "        # TODO have this step done in R import_data.R\n",
    "\n",
    "        if 'Normal' in labels:\n",
    "            for i, label in enumerate(labels):\n",
    "                if label != 'Normal':\n",
    "                    labels[i] = 'Not Normal'\n",
    "\n",
    "        categories = pd.Categorical(labels).codes\n",
    "        self.labels = pd.concat([\n",
    "            pd.DataFrame(np.array(samples).reshape([-1, 1])),\n",
    "            pd.DataFrame(np.array(categories).reshape([-1, 1])),\n",
    "            pd.DataFrame(np.array(labels).reshape([-1, 1])),\n",
    "        ], 1)\n",
    "        self.labels.columns = ['sample', 'category', 'label']\n",
    "        self.nb_classes = len(np.unique(self.labels['category']))\n",
    "        self.input_shape = [self.data.shape[1], n_channels]\n",
    "        self.criterion = criterion\n",
    "        self.step = 0\n",
    "        self.call_num = 0\n",
    "        self.previous_datasets = \"\"\n",
    "        if model_path != 'None':\n",
    "            self.model_path, self.previous_datasets = self.select_best_model(model_path)\n",
    "        else:\n",
    "            self.model_path = False\n",
    "        if self.previous_datasets == \"\":\n",
    "            self.datasets = self.dataset_name\n",
    "        else:\n",
    "            self.datasets = f\"{self.previous_datasets}_{self.dataset_name}\"\n",
    "        self.params = {}\n",
    "\n",
    "    # This function of class Train is not used to train the first model and is ommitted to simplify the code. \n",
    "    # Implemented and used notebook train_second_model (long).ipynb\n",
    "    def select_best_model(self, params_fname):\n",
    "        pass\n",
    "    \n",
    "    # This function of class Train is not used to train the first model and is ommitted to simplify the code. \n",
    "    # Implemented and used notebook train_second_model (long).ipynb\n",
    "    def update_model(self, model_source, path, wd):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def train(self, h_params):\n",
    "        self.call_num += 1\n",
    "        n_epochs = h_params[0]\n",
    "        lr = h_params[1]\n",
    "        wd = h_params[2]\n",
    "        l1 = h_params[3]\n",
    "        bs = h_params[4]\n",
    "\n",
    "        h_params = {\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"lr\": lr,\n",
    "            \"wd\": wd,\n",
    "            \"l1\": l1,\n",
    "            \"bs\": bs,\n",
    "        }\n",
    "\n",
    "        path = \\\n",
    "            f'{self.criterion}/' + \\\n",
    "            f'{n_epochs}/' \\\n",
    "            f'{\"{:.8f}\".format(float(lr))}/' \\\n",
    "            f'{\"{:.8f}\".format(float(wd))}/' \\\n",
    "            f'{bs}/'\n",
    "        dnn = self.model_name(h_params, self.nb_classes, variant=self.variant, activation='relu', batch_size=bs)\n",
    "        hparams_filepath = f\"logs/{dnn.get_model_name()}/{self.variant}/{self.datasets}/{self.freeze}/{self.retrain}\" \\\n",
    "                           f\"/hparam_tuning/{path}\"\n",
    "        log_filepath = f\"logs/{dnn.get_model_name()}/{self.variant}/{self.datasets}/{self.freeze}/{self.retrain}/{path}\"\n",
    "        del dnn\n",
    "        os.makedirs(log_filepath, exist_ok=True)\n",
    "        os.makedirs(hparams_filepath, exist_ok=True)\n",
    "        tb_logging = TensorboardLogging(hparams_filepath, h_params)\n",
    "\n",
    "        traces = {\n",
    "            \"train\": {\n",
    "                \"losses\": [],\n",
    "                \"accuracies\": [],\n",
    "                \"mccs\": [],\n",
    "                \"sensitivities\": [],\n",
    "                \"specificities\": [],\n",
    "            },\n",
    "            \"valid\": {\n",
    "                \"losses\": [],\n",
    "                \"accuracies\": [],\n",
    "                \"mccs\": [],\n",
    "                \"sensitivities\": [],\n",
    "                \"specificities\": [],\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"losses\": [],\n",
    "                \"accuracies\": [],\n",
    "                \"mccs\": [],\n",
    "                \"sensitivities\": [],\n",
    "                \"specificities\": [],\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        ################################################################\n",
    "        # BEGINNING OF PART DIFFERENT FROM CORRECT SPLIT\n",
    "        # Duplicates of the same biological sample will end up \n",
    "        # in all train/valid/test splits and lead to overfitting\n",
    "        ################################################################\n",
    "        \n",
    "        indices = np.array(list(range(len(self.labels['category']))))\n",
    "        np.random.shuffle(indices)\n",
    "        cutoff = int(len(indices) * 0.8)\n",
    "        all_train_indices = indices[:cutoff]\n",
    "        all_train_labels = self.labels['category'][all_train_indices].tolist()\n",
    "        test_indices = indices[cutoff:]\n",
    "        x_test = self.data[test_indices]\n",
    "        y_test = self.labels['category'][test_indices].tolist()\n",
    "\n",
    "        x_test = self.data[test_indices]\n",
    "        y_test = self.labels['category'][test_indices].tolist()\n",
    "\n",
    "        assert len(set(y_test)) == self.nb_classes\n",
    "\n",
    "        # 3 Fold-CV\n",
    "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "        for i, (train_samples, valid_samples) in enumerate(skf.split(all_train_samples, train_cats)):\n",
    "            # Just plot the first iteration, it will already be crowded if doing > 100 optimization iterations\n",
    "            if self.verbose:\n",
    "                print(f\"CV: {i}\")\n",
    "            # new_nums = [train_nums[i] for i in inds]\n",
    "\n",
    "            valid_samples = [all_train_samples[s] for s in valid_samples]\n",
    "            train_samples = [all_train_samples[s] for s in train_samples]\n",
    "            train_indices = [s for s, lab in enumerate(self.labels['sample'].tolist()) if lab in train_samples]\n",
    "            valid_indices = [s for s, lab in enumerate(self.labels['sample'].tolist()) if lab in valid_samples]\n",
    "\n",
    "            ################################################################\n",
    "            # END OF PART DIFFERENT FROM CORRECT SPLIT\n",
    "            ################################################################\n",
    "            \n",
    "            x_train = self.data[train_indices]\n",
    "            y_train = self.labels['category'][train_indices]\n",
    "            x_valid = self.data[valid_indices]\n",
    "            y_valid = self.labels['category'][valid_indices]\n",
    "\n",
    "            assert len(set(y_train)) == self.nb_classes and len(set(y_valid)) == self.nb_classes\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(x_train)\n",
    "            x_train = scaler.transform(x_train)\n",
    "            x_valid = scaler.transform(x_valid)\n",
    "\n",
    "            x_train_conv = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "            x_valid_conv = np.reshape(x_valid, (x_valid.shape[0], x_valid.shape[1], 1))\n",
    "            y_train_conv = to_categorical(y_train, self.nb_classes)\n",
    "            y_valid_conv = to_categorical(y_valid, self.nb_classes)\n",
    "\n",
    "            dnn = self.model_name(h_params, self.nb_classes, batch_size=bs, variant=self.variant, activation='relu')\n",
    "            dnn.build(input_shape=self.input_shape)\n",
    "\n",
    "            if self.model_path:\n",
    "                dnn = self.update_model(model_source=dnn, path=self.model_path, wd=wd)\n",
    "            dnn.model.compile(loss=self.criterion,\n",
    "                              optimizer=Adam(lr=lr, beta_1=0.99, beta_2=0.999, decay=wd, amsgrad=False),\n",
    "                              metrics=['accuracy', mcc])\n",
    "            callbacks = []\n",
    "            if i == 0:\n",
    "                callbacks += [keras.callbacks.TensorBoard(\n",
    "                    log_dir=log_filepath,\n",
    "                    histogram_freq=1,\n",
    "                    write_graph=True,\n",
    "                    write_images=False,\n",
    "                    update_freq=\"epoch\",\n",
    "                    profile_batch=2,\n",
    "                    embeddings_freq=0,\n",
    "                    embeddings_metadata=None,\n",
    "                )]\n",
    "            callbacks += [keras.callbacks.EarlyStopping(\n",
    "                monitor='loss',\n",
    "                min_delta=0,\n",
    "                patience=10,\n",
    "                verbose=self.verbose,\n",
    "                mode='min'\n",
    "            )]\n",
    "\n",
    "            y_integers = np.argmax(y_train_conv, axis=1)\n",
    "            class_weights = compute_class_weight('balanced', classes=np.unique(y_integers), y=y_integers)\n",
    "            d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "            # CAN't USE VALIDATION SPLIT, so also can't use early_stopping or reduceLROnPLateau\n",
    "            if self.verbose == 2:\n",
    "                fit_verbose = 1\n",
    "            else:\n",
    "                fit_verbose = 0\n",
    "            history = dnn.model.fit(\n",
    "                x=x_train_conv,\n",
    "                y=y_train_conv,\n",
    "                batch_size=bs,\n",
    "                verbose=fit_verbose,\n",
    "                epochs=n_epochs,\n",
    "                validation_split=0.,\n",
    "                class_weight=d_class_weights,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            base_path = f'saved_models/keras/{dnn.get_model_name()}/{self.variant}/{self.datasets}/' \\\n",
    "                        f'{self.freeze}/{self.retrain}/'\n",
    "            file_path = f'{base_path}/{path}'\n",
    "            os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "            train_acc = history.history['accuracy']\n",
    "            train_loss = history.history['loss']\n",
    "            train_mcc = history.history['mcc']\n",
    "            train_sensitivity = history.history['mcc']\n",
    "            train_mcc = history.history['mcc']\n",
    "\n",
    "            # train_loss, train_acc, train_mcc = dnn.model.evaluate(x_train_conv, y_train_conv, verbose=self.verbose)\n",
    "            y_classes_train = np.argmax(dnn.model.predict(x_train_conv), axis=-1)\n",
    "            train_sensitivity = sensitivity(y_train, y_classes_train)\n",
    "            train_specificity = specificity(y_train, y_classes_train)\n",
    "            \n",
    "            valid_loss, valid_acc, valid_mcc = dnn.model.evaluate(x_valid_conv, y_valid_conv, verbose=self.verbose)\n",
    "            y_classes_valid = np.argmax(dnn.model.predict(x_valid_conv), axis=-1)\n",
    "            valid_sensitivity = sensitivity(y_valid, y_classes_valid)\n",
    "            valid_specificity = specificity(y_valid, y_classes_valid)\n",
    "\n",
    "            best_epoch = np.argmin(valid_loss)\n",
    "\n",
    "            traces['train']['losses'].append(train_loss)\n",
    "            traces['train']['accuracies'].append(train_acc)\n",
    "            traces['train']['mccs'].append(train_mcc)\n",
    "            traces['train']['sensitivities'].append(train_sensitivity)\n",
    "            traces['train']['specificities'].append(train_specificity)\n",
    "            traces['valid']['losses'].append(valid_loss)\n",
    "            traces['valid']['accuracies'].append(valid_acc)\n",
    "            traces['valid']['mccs'].append(valid_mcc)\n",
    "            traces['valid']['sensitivities'].append(valid_sensitivity)\n",
    "            traces['valid']['specificities'].append(valid_specificity)\n",
    "\n",
    "        if self.retrain:\n",
    "            x_all_train = self.data[all_train_indices]\n",
    "            y_all_train = self.labels['category'][all_train_indices]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(x_all_train)\n",
    "            all_x_train = scaler.transform(x_all_train)\n",
    "\n",
    "            x_train_conv = np.reshape(all_x_train, (all_x_train.shape[0], all_x_train.shape[1], 1))\n",
    "            y_train_conv = to_categorical(y_all_train, self.nb_classes)\n",
    "\n",
    "            history = dnn.model.fit(\n",
    "                x=x_train_conv,\n",
    "                y=y_train_conv,\n",
    "                batch_size=bs,\n",
    "                verbose=fit_verbose,\n",
    "                epochs=n_epochs,\n",
    "                validation_split=0.,\n",
    "                class_weight=d_class_weights,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "\n",
    "        x_test_trans = scaler.transform(x_test)\n",
    "        x_test_conv = np.reshape(x_test_trans, (x_test_trans.shape[0], x_test_trans.shape[1], 1))\n",
    "        y_test_conv = to_categorical(y_test, self.nb_classes)\n",
    "\n",
    "        test_loss, test_acc, test_mcc = dnn.model.evaluate(x_test_conv, y_test_conv, verbose=self.verbose)\n",
    "        y_classes_test = np.argmax(dnn.model.predict(x_test_conv), axis=-1)\n",
    "        test_sensitivity = sensitivity(y_test, y_classes_test)\n",
    "        test_specificity = specificity(y_test, y_classes_test)\n",
    "        \n",
    "        traces['test']['losses'].append(test_loss)\n",
    "        traces['test']['accuracies'].append(test_acc)\n",
    "        traces['test']['mccs'].append(test_mcc)\n",
    "        traces['test']['specificities'].append(test_specificity)\n",
    "        traces['test']['sensitivities'].append(test_sensitivity)\n",
    "        # dnn.model.summary()\n",
    "\n",
    "        dnn.model.save_weights(f'{file_path}/{self.variant}_{self.cumulative_step}.h5')\n",
    "        self.step += 1\n",
    "\n",
    "        tb_logging.logging(traces)\n",
    "\n",
    "        self.params[f\"call_{self.call_num}\"] = {\n",
    "            'datasets': self.datasets,\n",
    "            'h_params': {\n",
    "                'criterion': f'{self.criterion}',\n",
    "                'n_epochs': f'{n_epochs}',\n",
    "                'lr': f'{lr}',\n",
    "                'bs': f'{bs}',\n",
    "                'wd': f'{wd}',\n",
    "                'l1': f'{l1}',\n",
    "            },\n",
    "            'scores': {\n",
    "                'best_epoch': f'{best_epoch}',\n",
    "                'train_loss': f'{train_loss[int(best_epoch)]}',\n",
    "                'valid_loss': f'{valid_loss}',\n",
    "                'test_loss': f'{test_loss}',\n",
    "                'train_acc': f'{train_acc[int(best_epoch)]}',\n",
    "                'valid_acc': f'{valid_acc}',\n",
    "                'test_acc': f'{test_acc}',\n",
    "                'train_mcc': f'{train_mcc[int(best_epoch)]}',\n",
    "                'valid_mcc': f'{valid_mcc}',\n",
    "                'test_mcc': f'{test_mcc}',\n",
    "            }\n",
    "        }\n",
    "        json.dump(self.params, open(f'{base_path}/{self.freeze}/{self.retrain}/params.json', 'w'))\n",
    "\n",
    "        return 1 - np.mean(traces['valid']['accuracies'])\n",
    "\n",
    "    def test(self, params):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-dodge",
   "metadata": {},
   "source": [
    "Use the following cell to launch tensorboard directly in the notebook. <br>\n",
    "If you have trouble lauching the tensorboard from the notebook, try launching it from a terminal with the command:<br>\n",
    "`tensorboard --logdir logs` <br>\n",
    "It is easier to use a dedicated tab to see the results anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "needed-reggae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9632), started 3:39:25 ago. (Use '!kill 9632' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/CNN/lecun/canis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "square-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the gpu is used. If empty list, no GPU available\n",
    "import tensorflow as tf \n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alive-moscow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f435c3c30925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m ]\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AirSim\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    257\u001b[0m             noise=noise)\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     return base_minimize(\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\AirSim\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a0b93ddf78ad>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, h_params)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0mfit_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             history = dnn.model.fit(\n\u001b[0m\u001b[0;32m    191\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train_conv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_conv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    964\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m    967\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1259\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3415\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3417\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3419\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[1;32m--> 757\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \"\"\"\n\u001b[1;32m--> 496\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    497\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    439\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m   \u001b[1;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m   \u001b[0msum_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    215\u001b[0m                                                       op.inputs[1])\n\u001b[0;32m    216\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape_kept_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(input, shape, name)\u001b[0m\n\u001b[0;32m    841\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m    844\u001b[0m         \"BroadcastTo\", input=input, shape=shape, name=name)\n\u001b[0;32m    845\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3526\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3528\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2013\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1824\u001b[0m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct_sequence_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1826\u001b[1;33m   op_desc = pywrap_tf_session.TF_NewOperation(graph._c_graph,\n\u001b[0m\u001b[0;32m   1827\u001b[0m                                               \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m                                               compat.as_str(node_def.name))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = Train(intensities_file='data/canis_intensities.csv',\n",
    "              cumulative_step=0,\n",
    "              criterion= 'categorical_crossentropy',\n",
    "              variant='lecun',\n",
    "              verbose=1,\n",
    "              model_name=CNN,\n",
    "              model_path='None',\n",
    "              freeze=True,\n",
    "              retrain=True\n",
    "              )\n",
    "\n",
    "os.makedirs(f'logs/hparam_tuning', exist_ok=True)\n",
    "\n",
    "from skopt.space import Real, Integer\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [\n",
    "    Integer(1, 50, \"uniform\", name='epochs'),\n",
    "    Real(1e-6, 1e-3, \"log-uniform\", name='lr'),\n",
    "    Real(1e-8, 1e-3, \"log-uniform\", name='wd'),\n",
    "    Real(1e-8, 1e-3, \"log-uniform\", name='l1'),\n",
    "    Integer(1, 512, \"uniform\", name='bs'),\n",
    "]\n",
    "\n",
    "test_mean = gp_minimize(train.train, space, n_calls=100, random_state=42)\n",
    "test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(params_fname):\n",
    "    # import from json file\n",
    "    params = pd.read_json(params_fname)\n",
    "    best_call = 0\n",
    "    best_valid_loss = np.inf\n",
    "    for call in list(params.keys()):\n",
    "        values = params[call]\n",
    "        if float(values['scores']['valid_loss']) < best_valid_loss:\n",
    "            best_valid_loss = float(values['scores']['valid_loss'])\n",
    "            best_call = call\n",
    "    hparams = params[best_call]['h_params']\n",
    "\n",
    "    return hparams\n",
    "\n",
    "# True and True for freezing the weights and retrain after cross-validation.\n",
    "# TODO save with meaningful folder names\n",
    "select_best_model(\"saved_models/keras/CNN/lecun/canis/True/True/params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-maker",
   "metadata": {},
   "source": [
    "To see the results, use tensorboard or (not recommended) change the verbose option to 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
